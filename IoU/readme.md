# ğŸ¯ IoU (Intersection over Union)

Based on the F-measure, there are two popular metrics for Medical Image Segmentation:
* Intersection-over-Union (IoU), also known as **Jaccard Index**
* Dice similarity coefficient, also known as **F1-score**

** IoU exhibits greater sensitivity to segmentation errors compared to DSC, applying stronger penalties to both excessive and insufficient segmentation predictions."

### What is IoU? ğŸ¤”
IoU, also known as the Jaccard Index, measures how much two masks overlap compared to their total combined area. Like comparing how well two stickers overlap when placed on top of each other!

### ğŸ“ Mathematical Formula

<div align="center">

```math
IoU = \frac{|A \cap B|}{|A \cup B|} = \frac{\text{Intersection}}{\text{Union}}
```

</div>

### ğŸ§® Components Breakdown

| Component | Symbol | Description | Visual |
|:---------:|:------:|:------------|:------:|
| Intersection | âˆ© | Pixels present in both masks | ğŸŸ¦ |
| Union | âˆª | Pixels present in either mask | ğŸŸ¨ |
| Prediction | A | Your model's output | ğŸ”µ |
| Ground Truth | B | The correct segmentation | ğŸ”´ |

### ğŸ“Š Score Interpretation

<div align="center">

| Score Range | Quality | Description | Grade |
|:----------:|:-------:|:------------|:-----:|
| 0.9 - 1.0 | Exceptional | Near-perfect overlap | ğŸ† |
| 0.8 - 0.9 | Excellent | Strong match | ğŸŒŸ |
| 0.7 - 0.8 | Good | Decent overlap | âœ¨ |
| 0.5 - 0.7 | Fair | Moderate match | â­ |
| < 0.5 | Poor | Significant mismatch | ğŸ“‰ |

</div>

### âœ¨ Key Features

- **Range**: [0, 1] where:
  - 1ï¸âƒ£ = Perfect match
  - 0ï¸âƒ£ = No overlap
- **Properties**:
  - âš–ï¸ Symmetric measure
  - ğŸ¯ Penalizes both over- and under-segmentation
  - ğŸ“ Scale-invariant

### ğŸ“ˆ Visual Examples

<div align="center">

```
Perfect IoU (1.0)       Good IoU (0.8)        Poor IoU (0.3)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   â”‚      â”‚  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    â”‚      â”‚â–ˆâ–ˆâ–ˆâ–ˆ    â–ˆâ–ˆâ–ˆâ–ˆ  â”‚
â”‚   â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   â”‚      â”‚   â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    â”‚      â”‚â–ˆâ–ˆâ–ˆâ–ˆ  â–ˆâ–ˆâ–ˆâ–ˆ    â”‚
â”‚   â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   â”‚      â”‚   â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    â”‚      â”‚  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

</div>

### ğŸš€ Common Use Cases

1. **Object Detection** 
   - Evaluating bounding box accuracy
   - Non-max suppression thresholds

2. **Semantic Segmentation**
   - Per-class evaluation
   - Overall model performance

3. **Instance Segmentation**
   - Individual object accuracy
   - Multi-object scenarios

### ğŸ’¡ Pro Tips

- ğŸ¯ Use Mean IoU (mIoU) for multi-class segmentation
- ğŸ” Consider class-wise IoU for imbalanced datasets
- âš¡ Optimize your model using IoU as a loss function
- ğŸ“Š Combine with other metrics for comprehensive evaluation

<div align="center">
  
  **Used in COCO, Pascal VOC, and other major computer vision benchmarks**
  
  [ğŸ“š Read More](docs/iou.md) | [ğŸ’» View Code](src/metrics.py) | [ğŸ¯ See Examples](examples/iou_examples.ipynb)
</div>

### ğŸ”— Related Metrics

- ğŸ“Š Dice Coefficient
- ğŸ“ˆ Pixel Accuracy
- ğŸ¯ Boundary F1-Score
